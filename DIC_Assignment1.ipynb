{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DIC Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP4VN429OeAFYph7JK/Oy4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditya0335/DIC-Assignment1/blob/master/DIC_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COsvtxGFf9lW",
        "colab_type": "code",
        "outputId": "b7d4795f-b72e-49e4-8eaf-d6d95b1b054f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaiPWQdvUfwo",
        "colab_type": "code",
        "outputId": "5c5c2386-7348-4f00-c553-354cbc122fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@c177635e71d9.(none)')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ0Ms-UiTExh",
        "colab_type": "text"
      },
      "source": [
        "Drive-bansaladitya0335@gmail.com"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHp6bw2Zj0c3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "os.chdir('/content/drive/My Drive/DIC ASSIGNMENT 1')\n",
        "data=pd.read_csv('data.csv')\n",
        "features=data.iloc[:,0:48]\n",
        "labels=data.iloc[:,48]\n",
        "features_train,features_test,labels_train,labels_test=train_test_split(features,labels,test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vQlIlK_wh1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c31ea451-518b-4ff5-9152-bbc0f1865e89"
      },
      "source": [
        "!git clone https://github.com/Deepesh7/Predictive-Analysis.git"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: remote origin already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60-odLEYS2EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# features = preprocessing.normalize(features)\n",
        "# features=scale(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17CW12tdSnHf",
        "colab_type": "code",
        "outputId": "b0c164cf-0239-4579-f748-8ed39a30bb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "features=np.asarray(features)\n",
        "features_train=np.asarray(features_train)\n",
        "features_test=np.asarray(features_test)\n",
        "labels_train=np.asarray(labels_train)\n",
        "labels_test=np.asarray(labels_test)\n",
        "print(features_test.shape)\n",
        "print(features_train.shape)\n",
        "# features_test_repeat=np.repeat(features_test,32764,0)\n",
        "# print(features_test_repeat.shape)\n",
        "row=features_train[:1,]\n",
        "print(row.shape)\n",
        "scaler = MinMaxScaler()\n",
        "features_train=scaler.fit_transform(features_train)\n",
        "features_test=scaler.transform(features_test)\n",
        "\n",
        "# for row in features_test:\n",
        "#   print(np.tile(row,reps=[32764,1])-features_train)\n",
        "  \n",
        "# features_train_repeat=np.tile(features_train,reps=)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8192, 48)\n",
            "(32764, 48)\n",
            "(1, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfdRXKD1eD-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KNN(X_train,X_test,Y_train):\n",
        "  testresult=[]\n",
        "  k_value=50\n",
        "  b=0\n",
        "  testresult_test=[]\n",
        "  for row in X_test:\n",
        "    distance=[]\n",
        "    knn = []\n",
        "    row=np.asarray(row)\n",
        "    row=row.reshape(1,48)\n",
        "    \n",
        "    # distance=np.sqrt(np.sum(np.subtract(np.tile(row,reps=[32764,1]),X_train),axis=1),axis=1)\n",
        "    distance=np.sqrt(np.sum(np.square((np.subtract(np.repeat(row,32764,0),X_train))),axis=1))\n",
        "    distance=distance.reshape(32764,1)\n",
        "    Y_train=Y_train.reshape(32764,1)\n",
        "    distance_Y_train=np.concatenate((Y_train,distance),axis=1)\n",
        "    distance_Y_train =  distance_Y_train[np.argsort(distance_Y_train[:, 1])]    \n",
        "    knn = distance_Y_train[:k_value]\n",
        "    knn=knn[:,0]\n",
        "    knn=knn.astype(int)\n",
        "    # print(np.bincount(knn).argmax())\n",
        "    testresult_test=np.append(testresult_test,np.bincount(knn).argmax())\n",
        "  return testresult_test\n",
        "result=KNN(features_train,features_test,labels_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKAmY27E1uoU",
        "colab_type": "code",
        "outputId": "3047282a-d501-4ca7-be44-c8dd5ef97e47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "print(accuracy_score(labels_test,result))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9776611328125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeAu03vAoVpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozkBlP0VuMQy",
        "colab_type": "text"
      },
      "source": [
        "Deepesh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYtKaR4fRzLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Predicitve_Analytics.py\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def Accuracy(y_true,y_pred):\n",
        "  size=y_true.size\n",
        "  \n",
        "    # \"\"\"\n",
        "    # :type y_true: numpy.ndarray\n",
        "    # :type y_pred: numpy.ndarray\n",
        "    # :rtype: float\n",
        "    \n",
        "    # \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAvAYel9uNcw",
        "colab_type": "text"
      },
      "source": [
        "Pooja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2gCHJ9ESLfo",
        "colab_type": "code",
        "outputId": "715b3e1f-933d-40bb-d6e6-afb02bd6a145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def Recall(y_true,y_pred):\n",
        "  classes=np.unique(y_true)\n",
        "  size=len(y_pred)\n",
        "  true_positive=0\n",
        "  false_negative=0\n",
        "  recall=0\n",
        "  for c in classes:\n",
        "    for i in range(size):\n",
        "      if y_true[i]==c and y_pred[i]==c:\n",
        "        true_positive +=1\n",
        "      if y_true[i]==c and y_pred[i]!=c:\n",
        "        false_negative +=1\n",
        "    if (true_positive==0 and false_negative==0):\n",
        "      recall=0\n",
        "    else:\n",
        "      recall+=true_positive/(true_positive+false_negative)\n",
        "  return recall/len(classes)\n",
        "result=result.astype(int)\n",
        "print(Recall(labels_test,result))\n",
        "print(recall_score(labels_test,result,average='macro'))\n",
        "    #  \"\"\"\n",
        "    # :type y_true: numpy.ndarray\n",
        "    # :type y_pred: numpy.ndarray\n",
        "    # :rtype: float\n",
        "    # \"\"\"\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9787535343396627\n",
            "0.9779098872944286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv0knvguuM8T",
        "colab_type": "text"
      },
      "source": [
        "Aditya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGaokWloRzbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a142dc76-974e-455c-97a9-cb60dce11d78"
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "def Precision(y_true,y_pred):\n",
        "  classes=np.unique(y_true)\n",
        "  size=len(y_pred)\n",
        "  true_positive=0\n",
        "  false_positive=0\n",
        "  precision=0\n",
        "  for c in classes:\n",
        "    for i in range(size):\n",
        "      if y_true[i]==c and y_pred[i]==c:\n",
        "        true_positive +=1\n",
        "      if y_true[i]!=c and y_pred[i]==c:\n",
        "        false_positive +=1\n",
        "    if (true_positive==0 and false_positive==0):\n",
        "      precision=0\n",
        "    else:\n",
        "      precision+=true_positive/(true_positive+false_positive)\n",
        "  return precision/len(classes)\n",
        "result=result.astype(int)\n",
        "\n",
        "print(Precision(labels_test,result))\n",
        "print(precision_score(labels_test,result,average='macro'))\n"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9730574853928385\n",
            "0.9781589935498108\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h-nxN_JuQNZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvl9L94WRzlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def WCSS(Clusters):\n",
        "    \"\"\"\n",
        "    :Clusters List[numpy.ndarray]\n",
        "    :rtype: float\n",
        "    \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olVSVOZVuPgH",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Iq823RShJf",
        "colab_type": "code",
        "outputId": "72d7f9b5-8247-4adc-ab7a-357ecf424e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "def ConfusionMatrix(y_true,y_pred):\n",
        "  unique_val=np.unique(y_true)\n",
        "  no_class = len(unique_val)\n",
        "  y_true=y_true-1\n",
        "  y_pred=y_pred-1\n",
        "\n",
        "  confusion_matrix=y_true*no_class+y_pred\n",
        "  con_matrix= np.zeros(no_class**2)\n",
        "  for i in range(len(confusion_matrix)): \n",
        "    index=confusion_matrix[i]\n",
        "    count=np.count_nonzero(confusion_matrix==(index))\n",
        "    con_matrix[index]=count\n",
        "\n",
        "  con_matrix_reshape=np.reshape(con_matrix, (no_class,no_class))\n",
        "  return con_matrix_reshape\n",
        "\n",
        "result=result.astype(int)\n",
        "print(ConfusionMatrix(labels_test,result))  \n",
        "    # \"\"\"\n",
        "    # :type y_true: numpy.ndarray\n",
        "    # :type y_pred: numpy.ndarray\n",
        "    # :rtype: float\n",
        "    # \"\"\" \n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8192,)\n",
            "(8192,)\n",
            "[[709.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.]\n",
            " [  1. 712.   0.   0.   0.   0.   0.   0.   1.  24.   0.]\n",
            " [  0.   0. 705.   1.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  0.   0.   1. 732.   0.   0.   0.   0.   0.   0.   0.]\n",
            " [  1.   0.   2.   9. 706.   0.   0.   7.   0.   0.   0.]\n",
            " [  7.   0.   0.   0.   0. 758.   0.   0.   9.   0.   0.]\n",
            " [  0.   0.   0.   0.   0.   0. 775.   0.   0.   0.   0.]\n",
            " [  0.   0.   0.   3.  12.   1.   0. 730.   0.   0.   0.]\n",
            " [  3.   2.   0.   0.   0.  28.   0.   0. 728.   1.   0.]\n",
            " [  0.  50.   0.   0.   0.   0.   0.   0.   0. 724.   0.]\n",
            " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 730.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3SGEPaDu1BJ",
        "colab_type": "text"
      },
      "source": [
        "Aditya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc-BfWb0uoSD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSj7vFyl4ESz",
        "colab_type": "text"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w35nLO-BOHje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_train=np.asarray(features_train)\n",
        "features_test=np.asarray(features_test)\n",
        "labels_train=np.asarray(labels_train)\n",
        "labels_test=np.asarray(labels_test)\n",
        "\n",
        "def gini_number(data):\n",
        "  classes=np.unique(data[:,-1]) \n",
        "  size=len(data)\n",
        "  # print(data.shape)\n",
        "  score=0\n",
        "  for class_values in classes:\n",
        "    score =score + np.square(np.count_nonzero(data[:,-1]== class_values)/size)\n",
        "  gini=1-score\n",
        "  return gini\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "def information_gain(dataset):\n",
        "  # print(dataset.shape)\n",
        "  percent=[10,20,30,40,50,60,70,80,90]\n",
        "  i=-1\n",
        "  gain=-9999\n",
        "  left_data= None\n",
        "  right_data= None\n",
        "  new=[]\n",
        "  datafeatures=dataset[:,0:dataset.shape[1]-1]\n",
        "  #print(dataset.shape[1])\n",
        "  left_gini,right_gini=0,0\n",
        "  # value\n",
        "  # index_column\n",
        "  for column in datafeatures.T:\n",
        "\n",
        "    i+=1\n",
        "    # new=np.column_stack((features_train[:,i],labels_train))\n",
        "\n",
        "    n_instances=float(len(dataset))\n",
        "    if(n_instances<=1):\n",
        "      continue\n",
        "    gini_column=gini_number(dataset[:,[i,-1]])\n",
        "    for percentile in percent:\n",
        "      \n",
        "      \n",
        "      new=np.argsort(dataset[:,i])\n",
        "      split=np.percentile(dataset[:,i],percentile)\n",
        "      left=dataset[dataset[:,i]<split]\n",
        "      left_size=float(len(left))\n",
        "      right=dataset[dataset[:,i]>=split]\n",
        "      right_size=float(len(right))\n",
        "      # if(left_size > 0):\n",
        "      left_gini=gini_number(left)\n",
        "      # if (right_size > 0):\n",
        "      right_gini=gini_number(right)\n",
        "      weighted_gini=left_gini*(left_size/n_instances)+right_gini*(right_size/n_instances)\n",
        "      info_gain=gini_column-weighted_gini\n",
        "      if(info_gain>gain):\n",
        "        gain,left_data,right_data,index_column,value=info_gain,left,right,i,split\n",
        "  # print(index_column,value)\n",
        "  return {'gain':gain,'left':left_data,'right':right_data,'index':index_column,'value':value}\n",
        "\n",
        "def splitting(node,max_depth):\n",
        "  # print(type(node['left']))\n",
        "  # print(node['left'])\n",
        "  depth=10\n",
        "  minsize=2   \n",
        "  left=node['left']\n",
        "  right=node['right']\n",
        "  del(node['left'])\n",
        "  del(node['right'])\n",
        "  left_label=left[:,-1]\n",
        "  left_label=left_label.astype(int)\n",
        "  right_label=right[:,-1]\n",
        "  right_label=right_label.astype(int)\n",
        "  values=[]\n",
        "  if(len(left)==0 or len(right)==0):\n",
        "    values=np.concatenate((left,right))\n",
        "    vl=values[:,-1].astype(int)\n",
        "    final_label=np.bincount(vl).argmax()\n",
        "    node['left']=node['right']=final_label\n",
        "    # print(node['left'])\n",
        "    return\n",
        "  if(max_depth>=depth):\n",
        "    node['left']=np.bincount(left_label).argmax()\n",
        "    # print(node['left'])\n",
        "    node['right']=np.bincount(right_label).argmax()\n",
        "    # print(node['right'])\n",
        "    return\n",
        "  if(minsize>=len(left)):\n",
        "    node['left']=np.bincount(left_label).argmax()\n",
        "    # print(node['left'])\n",
        "  else:\n",
        "    node['left']=information_gain(left)\n",
        "    d=max_depth+1\n",
        "    splitting(node['left'],d)\n",
        "  if(minsize>=len(right)):\n",
        "    node['right']=np.bincount(right_label).argmax()\n",
        "    # print(node['right'])\n",
        "  else:\n",
        "    node['right']=information_gain(right)\n",
        "    d=max_depth+1\n",
        "    splitting(node['right'],d)\n",
        "  # if(minsize<=right(left)):\n",
        "  #   node[2]=np.bincount(right_label).argmax()\n",
        "\n",
        "def predictions(root,row):\n",
        "  if (row[root['index']]>root['value']):\n",
        "    if isinstance(root['right'],dict):\n",
        "      pred_val=predictions(root['right'],row)\n",
        "    else:\n",
        "      #print(root['right'])\n",
        "      pred_val=root['right']\n",
        "  else:\n",
        "    if isinstance(root['left'],dict):\n",
        "      pred_val=predictions(root['left'],row)\n",
        "    else:\n",
        "      #print(root['left'])\n",
        "      pred_val=root['left']\n",
        "  return pred_val\n",
        "\n",
        "\n",
        "def decision_tree(data,test):\n",
        "  \n",
        "  node=information_gain(data)\n",
        "  splitting(node,1)\n",
        "  #print(node)\n",
        "  test_predictions=[]\n",
        "  for row in test:\n",
        "    predicted=predictions(node,row)\n",
        "    #print(predicted)\n",
        "    test_predictions=np.append(test_predictions,predicted)\n",
        "  return test_predictions\n",
        "  # print(node)\n",
        "\n",
        "\n",
        "\n",
        "# node=information_gain(data.values)\n",
        "# decision_tree(features_train,labels_train,features_test)\n",
        "#print()\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymwq3W5HG-XW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fadce33-7e61-4699-a991-cb0ee4a83e26"
      },
      "source": [
        "def RandomForest(X_train,Y_train,X_test):\n",
        "  epochs=10\n",
        "  total_predictions=[]\n",
        "  predicted_label=[]\n",
        "  for i in range(epochs):\n",
        "    features_for_split=np.sqrt(np.size(X_train,1)) #7 features\n",
        "    #print(features_for_split)\n",
        "    index=np.arange(X_train.shape[1])\n",
        "    random_sample=np.random.choice(index,size=features_for_split.astype(int),replace=True)\n",
        "    random_features=features_train[:,random_sample]\n",
        "    #print(random_features.shape)\n",
        "    test_features=X_test[:,random_sample]\n",
        "    total_data=np.column_stack((random_features,Y_train))\n",
        "    index_bootstrap=np.arange(X_train.shape[0])\n",
        "    bootstrap_sample=np.random.choice(index_bootstrap,X_train.shape[0],replace=True)\n",
        "    \n",
        "    bootstrap_data=total_data[bootstrap_sample,:]\n",
        "    #print(bootstrap_data.shape)\n",
        "    total_predictions=np.append(total_predictions,decision_tree(bootstrap_data,test_features))\n",
        "    # print(total_predictions.shape)\n",
        "  total_predictions=total_predictions.reshape(epochs,X_test.shape[0])\n",
        "  total_predictions=total_predictions.astype(int)\n",
        "  # print(total_predictions)\n",
        "  for row in total_predictions.T:\n",
        "    predicted_label=np.append(predicted_label,np.bincount(row).argmax())\n",
        "  return predicted_label\n",
        "  \n",
        "  \n",
        "# print(labels_test.shape)\n",
        "labels_predict=RandomForest(features_train,labels_train,features_test)\n",
        "# print(labels_predict.shape)\n",
        "print(accuracy_score(labels_test,labels_predict))\n",
        "  \n",
        "    # \"\"\"\n",
        "    # :type X_train: numpy.ndarray\n",
        "    # :type X_test: numpy.ndarray\n",
        "    # :type Y_train: numpy.ndarray\n",
        "    \n",
        "    # :rtype: numpy.ndarray\n",
        "    # \"\"\""
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9146728515625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAVLC1oZumja",
        "colab_type": "text"
      },
      "source": [
        "Pooja"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1sd3ZLUShS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3949fa95-420c-45fa-ab8a-14ea73792fe5"
      },
      "source": [
        "def PCA(X_train,N):\n",
        "    mean_Val = np.mean(X_train)\n",
        "    X_train_mean=X_train-mean_Val\n",
        "    u,s,vh = np.linalg.svd(X_train_mean, full_matrices=False)\n",
        "    vh=vh.T\n",
        "    S=np.diag(s)\n",
        "    PCA_array = u[:, 0:N].dot(S[0:N, 0:N])\n",
        "    return PCA_array\n",
        "    # \"\"\"\n",
        "    # :type X_train: numpy.ndarray\n",
        "    # :type N: int\n",
        "    # :rtype: numpy.ndarray\n",
        "    # \"\"\""
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.80899866 -0.97319046 -0.5198029  -0.13335396  0.01226552]\n",
            " [-1.70718706 -0.75001261 -0.23565801 -0.06914143 -0.0288503 ]\n",
            " [-1.75438486  0.08561008  0.1374438   0.12996271  0.04488621]\n",
            " ...\n",
            " [-1.91909963  0.70648457 -0.17498945  0.00307458 -0.14257381]\n",
            " [-1.72978258 -0.47746372  0.06421288  0.1703747   0.10250725]\n",
            " [-1.89899469  0.20191737 -0.23136465  0.08107682  0.05495291]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJiGKVrFusad",
        "colab_type": "text"
      },
      "source": [
        "Deepesh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWghtJJzShVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Kmeans(X_train,N):\n",
        "    \"\"\"\n",
        "    :type X_train: numpy.ndarray\n",
        "    :type N: int\n",
        "    :rtype: List[numpy.ndarray]\n",
        "    \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rBr8-KCRzt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SklearnSupervisedLearning(X_train,Y_train,X_test):\n",
        "    \"\"\"\n",
        "    :type X_train: numpy.ndarray\n",
        "    :type X_test: numpy.ndarray\n",
        "    :type Y_train: numpy.ndarray\n",
        "    \n",
        "    :rtype: List[numpy.ndarray] \n",
        "    \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qkwUAORz2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SklearnVotingClassifier(X_train,Y_train,X_test):\n",
        "    \n",
        "    \"\"\"\n",
        "    :type X_train: numpy.ndarray\n",
        "    :type X_test: numpy.ndarray\n",
        "    :type Y_train: numpy.ndarray\n",
        "    \n",
        "    :rtype: List[numpy.ndarray] \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Create your own custom functions for Matplotlib visualization of hyperparameter search. \n",
        "Make sure that plots are labeled and proper legends are used\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}